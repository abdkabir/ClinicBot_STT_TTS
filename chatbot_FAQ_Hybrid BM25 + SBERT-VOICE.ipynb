{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5b4ef5-ca65-4506-915c-ee20928dcf47",
   "metadata": {},
   "source": [
    "hybrid_bm25_sbert_chatbot (Hybrid BM25 + SBERT: Untuk hasil maksimal.)\n",
    "Penjelasan:\n",
    ">BM25 mengambil 5 kandidat teratas berdasarkan keyword.\n",
    ">SBERT menghitung similarity semantic antara pertanyaan user dan kandidat.\n",
    ">Top 3 jawaban paling mirip ditampilkan, urut berdasarkan kemiripan semantic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c654a6-56ca-4b92-9330-c418915e6e80",
   "metadata": {},
   "source": [
    "Tahapan yang Ada di Kode\n",
    "-----------\n",
    ">1 Load Dataset (read file JSON).\n",
    ">2 Preprocessing ringan: Tokenisasi dan lowercase untuk BM25.\n",
    ">3 Indexing: Membuat objek BM25 dan menghasilkan embedding SBERT.\n",
    ">4 Inference: Mengambil pertanyaan user, melakukan pencarian hybrid, dan mengembalikan jawaban.\n",
    ">5 STT & TTS: Hanya untuk input/output, tidak ada preprocessing data.\n",
    "\n",
    "\n",
    "Kesimpulan\n",
    "------\n",
    ">1 Tidak ada tahapan preprocessing yang kompleks.\n",
    ">2 Tidak ada pelatihan model (epoch/training).\n",
    ">3 Semua model yang digunakan (BM25 & SBERT) hanya untuk pencarian dan inference, bukan training ulang."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9cb8be-433a-481c-8f97-6bba97f1c767",
   "metadata": {},
   "source": [
    "Contoh Penulisan di Judul atau Subjudul:\n",
    "---------\n",
    ">“Pengembangan ClinicBot Hybrid berbasis BM25 dan BERT untuk Optimalisasi Pembelajaran Klinik Non-Fungsional”\n",
    "\n",
    ">“ClinicBot: Hybrid Context-Aware Conversational Agent untuk Pembelajaran Klinik Manekin berbasis STT-TTS dan IoT”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78a1c14-3d3e-4b35-8ced-8d63b722017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pyttsx3\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494c96ae-c059-47fb-b2c0-bb81912f3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LOAD DATASET =====\n",
    "with open(\"data/pertanyaan_jawaban.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    faq_data = json.load(f)\n",
    "\n",
    "faq_questions = [item[\"pertanyaan\"] for item in faq_data]\n",
    "faq_answers = [item[\"jawaban\"] for item in faq_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd635b6-73fc-4d13-8432-6b1aedf739bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== INISIALISASI BM25 DAN SBERT =====\n",
    "tokenized_questions = [q.lower().split() for q in faq_questions]\n",
    "bm25 = BM25Okapi(tokenized_questions)\n",
    "sbert_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "faq_embeddings = sbert_model.encode(faq_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc869baa-8fd1-41c5-b1c4-9c8340eb6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== INISIALISASI TTS =====\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 145)  # kecepatan bicara\n",
    "\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# ===== INISIALISASI STT =====\n",
    "def listen():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Silakan bicara...\")\n",
    "        audio = recognizer.listen(source, timeout=5)\n",
    "        print(\"Mendengarkan...\")\n",
    "    try:\n",
    "        query = recognizer.recognize_google(audio, language=\"id-ID\")\n",
    "        print(f\"Kamu berkata: {query}\")\n",
    "        return query\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Maaf, suara tidak terbaca.\")\n",
    "        speak(\"Maaf, suara tidak terbaca.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print(\"Gagal menghubungi layanan STT.\")\n",
    "        speak(\"Gagal menghubungi layanan STT.\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f69f7db6-8380-4b92-a17e-121318a34386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot Hybrid BM25 + SBERT (FAQ + STT & TTS)\n",
      "----------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pilih mode (1 = ketik, 2 = suara):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silakan bicara...\n",
      "Mendengarkan...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamu berkata: halo\n",
      "\n",
      "Top jawaban paling relevan:\n",
      "\n",
      "1. Pertanyaan mirip: Apa itu BERT?\n",
      "   Jawaban       : BERT adalah model transformer untuk NLP yang dikembangkan oleh Google.\n",
      "   Skor kemiripan: 0.3999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdulkabir/.pyenv/versions/3.10.13/lib/python3.10/site-packages/sentence_transformers/util.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  a = torch.tensor(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Pertanyaan mirip: Bagaimana cara kerja chatbot?\n",
      "   Jawaban       : Chatbot memproses input pengguna dan menghasilkan respons otomatis, bisa berbasis aturan atau AI.\n",
      "   Skor kemiripan: 0.2805\n",
      "\n",
      "3. Pertanyaan mirip: Apa perbedaan supervised dan unsupervised learning?\n",
      "   Jawaban       : Supervised learning menggunakan data berlabel, sedangkan unsupervised learning tidak menggunakan label.\n",
      "   Skor kemiripan: 0.0615\n",
      "Silakan bicara...\n",
      "Mendengarkan...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamu berkata: Apakah anda mengalami\n",
      "\n",
      "Top jawaban paling relevan:\n",
      "\n",
      "1. Pertanyaan mirip: Apakah Anda mengalami diare atau sakit perut?\n",
      "   Jawaban       : Sering diare dan sakit perut hebat.\n",
      "   Skor kemiripan: 0.6672\n",
      "\n",
      "2. Pertanyaan mirip: Apakah Anda mengalami perdarahan dari gusi atau hidung?\n",
      "   Jawaban       : Ya, saya sering mengalami pendarahan di gusi dan hidung.\n",
      "   Skor kemiripan: 0.6210\n",
      "\n",
      "3. Pertanyaan mirip: Apakah Anda merasa kulit Anda berubah atau mengalami ruam?\n",
      "   Jawaban       : Saya mengalami ruam pada kulit dan merasa lelah.\n",
      "   Skor kemiripan: 0.5924\n",
      "Silakan bicara...\n",
      "Mendengarkan...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamu berkata: Apakah anda merasa le\n",
      "\n",
      "Top jawaban paling relevan:\n",
      "\n",
      "1. Pertanyaan mirip: Apakah Anda merasa leher Anda kaku?\n",
      "   Jawaban       : Saya mengalami demam tinggi disertai mual.\n",
      "   Skor kemiripan: 0.6583\n",
      "\n",
      "2. Pertanyaan mirip: Apakah Anda merasa kesulitan berbicara?\n",
      "   Jawaban       : Ya, saya merasa kesulitan untuk berbicara, lidah terasa berat.\n",
      "   Skor kemiripan: 0.6165\n",
      "\n",
      "3. Pertanyaan mirip: Apakah Anda merasa kulit Anda berubah atau mengalami ruam?\n",
      "   Jawaban       : Saya mengalami ruam pada kulit dan merasa lelah.\n",
      "   Skor kemiripan: 0.5773\n",
      "Silakan bicara...\n",
      "Mendengarkan...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamu berkata: Apakah anda merasa Lemah atau dehidrasi\n",
      "\n",
      "Top jawaban paling relevan:\n",
      "\n",
      "1. Pertanyaan mirip: Apakah Anda merasa lemah atau dehidrasi?\n",
      "   Jawaban       : Saya merasa sangat lemah dan dehidrasi.\n",
      "   Skor kemiripan: 0.9638\n",
      "\n",
      "2. Pertanyaan mirip: Apakah Anda merasa mual atau muntah?\n",
      "   Jawaban       : Ya, saya merasa mual dan terkadang muntah.\n",
      "   Skor kemiripan: 0.7118\n",
      "\n",
      "3. Pertanyaan mirip: Apakah Anda sering merasa lelah atau pusing?\n",
      "   Jawaban       : Sering merasa sangat lelah dan pusing.\n",
      "   Skor kemiripan: 0.6304\n",
      "Silakan bicara...\n",
      "Mendengarkan...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamu berkata: selesai\n"
     ]
    }
   ],
   "source": [
    "def hybrid_search(user_question, bm25_top_n=5, sbert_top_k=3):\n",
    "    # Step 1. BM25 retrieval\n",
    "    tokenized_query = user_question.lower().split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    bm25_top_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:bm25_top_n]\n",
    "\n",
    "    # Step 2. SBERT rerank\n",
    "    candidate_questions = [faq_questions[i] for i in bm25_top_indices]\n",
    "    candidate_answers = [faq_answers[i] for i in bm25_top_indices]\n",
    "    candidate_embeddings = [faq_embeddings[i] for i in bm25_top_indices]\n",
    "    user_embedding = sbert_model.encode([user_question])[0]\n",
    "    cos_sims = util.cos_sim(user_embedding, candidate_embeddings)[0].cpu().tolist()\n",
    "\n",
    "    # Pair and rerank\n",
    "    pairs = list(zip(bm25_top_indices, candidate_questions, candidate_answers, cos_sims))\n",
    "    pairs = sorted(pairs, key=lambda x: x[3], reverse=True)  # sort by SBERT cosine similarity\n",
    "\n",
    "    # Ambil top K hasil\n",
    "    return pairs[:sbert_top_k]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Chatbot Hybrid BM25 + SBERT (FAQ + STT & TTS)\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    mode = input(\"Pilih mode (1 = ketik, 2 = suara): \")\n",
    "    while True:\n",
    "        if mode == \"2\":\n",
    "            user_question = listen()\n",
    "            if user_question == \"\":\n",
    "                continue\n",
    "        else:\n",
    "            user_question = input(\"\\nTulis pertanyaanmu (atau ketik 'selesai' untuk keluar): \")\n",
    "        if user_question.lower() == \"selesai\":\n",
    "            speak(\"Okey, senang berbicara dengan anda, Sampai jumpa lagi!\")\n",
    "            break\n",
    "        results = hybrid_search(user_question)\n",
    "        print(\"\\nTop jawaban paling relevan:\")\n",
    "        for i, (idx, q, a, score) in enumerate(results, 1):\n",
    "            print(f\"\\n{i}. Pertanyaan mirip: {q}\")\n",
    "            print(f\"   Jawaban       : {a}\")\n",
    "            print(f\"   Skor kemiripan: {score:.4f}\")\n",
    "            if i == 1:  # hanya jawaban teratas di-TTS\n",
    "                speak(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba13043-15e6-4bbb-a07e-04acab9af728",
   "metadata": {},
   "source": [
    "Penjelasan Singkat\n",
    "------------\n",
    ">Epoch hanya relevan jika kamu ingin melatih (training) model machine learning/deep learning dari awal (misal: fine-tuning SBERT di dataset sendiri).\n",
    "Dalam kode kamu, SBERT hanya digunakan untuk inference (mengambil embedding), bukan untuk training ulang. Model SBERT yang dipakai sudah pre-trained dari HuggingFace.\n",
    "BM25 tidak ada proses training apalagi epoch, hanya membuat index dari data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9cbe23-535d-4045-9de8-11a20947c3ee",
   "metadata": {},
   "source": [
    "1. Tahapan Preprocessing\n",
    "- Preprocessing biasanya mengacu pada pembersihan, normalisasi, tokenisasi, stemming, dll.<br>\n",
    "- Pada kode kamu, preprocessing hanya berupa:\n",
    "    - Tokenisasi sederhana: q.lower().split() untuk BM25 (memecah kalimat jadi kata dan lowercase).\n",
    "    - Tidak ada stemming, stopword removal, atau normalisasi lanjutan.\n",
    "- Tidak ada proses cleaning data secara mendalam.\n",
    "\n",
    "2. Tahapan Training / Epoch\n",
    "- Epoch adalah istilah dalam pelatihan model (training), di mana seluruh dataset dilalui satu kali untuk mengupdate bobot model.\n",
    "- Pada kode kamu:\n",
    "    - BM25: Tidak butuh training/epoch, hanya membuat index berdasarkan token.\n",
    "    - SBERT: Model SentenceTransformer sudah pre-trained dan hanya digunakan untuk melakukan encoding (inference) saja, bukan training ulang.\n",
    "    - Tidak ada proses training, fitting, atau epoch yang dilakukan pada dataset kamu.\n",
    "\n",
    "3. Tahapan yang Ada di Kode\n",
    "- Load Dataset (read file JSON).\n",
    "- Preprocessing ringan: Tokenisasi dan lowercase untuk BM25.\n",
    "- Indexing: Membuat objek BM25 dan menghasilkan embedding SBERT.\n",
    "- Inference: Mengambil pertanyaan user, melakukan pencarian hybrid, dan mengembalikan jawaban.\n",
    "- STT & TTS: Hanya untuk input/output, tidak ada preprocessing data.\n",
    "\n",
    "4. Kesimpulan\n",
    "- Tidak ada tahapan preprocessing yang kompleks.\n",
    "- Tidak ada pelatihan model (epoch/training).\n",
    "- Semua model yang digunakan (BM25 & SBERT) hanya untuk pencarian dan inference, bukan training ulang.\n",
    "\n",
    "Tidak, tidak diharuskan menggunakan epoch jika konteks penelitian atau aplikasi kamu adalah chatbot retrieval-based seperti di kode yang kamu pakai (BM25 + SBERT untuk pencocokan pertanyaan dan jawaban).\n",
    "\n",
    "Penjelasan Singkat =\n",
    "- Epoch hanya relevan jika kamu ingin melatih (training) model machine learning/deep learning dari awal (misal: fine-tuning SBERT di dataset sendiri).\n",
    "- Dalam kode kamu, SBERT hanya digunakan untuk inference (mengambil embedding), bukan untuk training ulang. Model SBERT yang dipakai sudah pre-trained dari HuggingFace.\n",
    "- BM25 tidak ada proses training apalagi epoch, hanya membuat index dari data.\n",
    "\n",
    "Dalam Penelitian/Tesis\n",
    "- Jika penelitian kamu berfokus pada implementasi, perbandingan retrieval, atau evaluasi sistem chatbot berbasis FAQ (bukan pada pelatihan model baru), maka tidak perlu ada proses epoch.\n",
    "- Kamu cukup jelaskan bahwa model SBERT yang digunakan sudah pre-trained dan hanya dipakai untuk pencocokan semantic, serta proses retrieval dilakukan dengan hybrid BM25 + SBERT.\n",
    "\n",
    "Kapan Butuh Epoch?\n",
    "- Jika kamu ingin melatih model baru (misal: fine-tune SBERT dengan data sendiri, atau buat neural retriever baru), barulah kamu perlu epoch dan tahapan training.\n",
    "- Biasanya ini untuk penelitian yang ingin membandingkan hasil fine-tuned model vs pre-trained model.\n",
    "\n",
    "Kesimpulan\n",
    "- Tidak perlu epoch kalau hanya melakukan retrieval seperti kode di atas.\n",
    "- Epoch hanya diperlukan untuk training/fine-tuning model, bukan untuk aplikasi retrieval-based FAQ chatbot seperti kode kamu.\n",
    "\n",
    "Saran untuk penulisan tesis:\n",
    "- Jelaskan bahwa model SBERT yang digunakan sudah “pre-trained” dan digunakan hanya untuk tahap pencocokan semantic (inference), sehingga tidak ada proses pelatihan (training) dan epoch dalam implementasi ini. Jelaskan juga keuntungan dan keterbatasan pendekatan seperti ini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076f4ca-6a25-4aa9-b0fd-e5565d94b113",
   "metadata": {},
   "source": [
    "-----------------------------------------------\n",
    "## METODOLOGI PENELITIAN\n",
    "\n",
    "### 3.1 Desain Penelitian  \n",
    "Penelitian ini menggunakan desain penelitian rekayasa perangkat lunak untuk membangun sebuah sistem chatbot berbasis hybrid retrieval pada Frequently Asked Questions (FAQ) dengan dukungan teknologi Speech-to-Text (STT) dan Text-to-Speech (TTS). Sistem dirancang untuk menjawab pertanyaan pengguna secara otomatis baik melalui input teks maupun suara, serta memberikan respons dalam bentuk teks dan suara.\n",
    "\n",
    "### 3.2 Alur Penelitian  \n",
    "Alur metodologi penelitian yang digunakan meliputi tahapan sebagai berikut:  \n",
    "1. Studi literatur dan pengumpulan data FAQ.\n",
    "2. Preprocessing data dan pembuatan dataset.\n",
    "3. Implementasi chatbot hybrid (BM25 + SBERT).\n",
    "4. Integrasi fitur STT dan TTS.\n",
    "5. Evaluasi sistem.\n",
    "\n",
    "### 3.3 Pengumpulan Data  \n",
    "Data yang digunakan berupa kumpulan pertanyaan dan jawaban (FAQ) yang diperoleh dari sumber resmi institusi atau website terkait. Data disimpan dalam format JSON untuk memudahkan pemrosesan.\n",
    "\n",
    "### 3.4 Preprocessing Data  \n",
    "Preprocessing yang dilakukan pada data FAQ meliputi:  \n",
    "- Lowercasing (mengubah seluruh teks menjadi huruf kecil)\n",
    "- Tokenisasi (memecah kalimat menjadi kata) untuk kebutuhan BM25\n",
    "- Pembuatan embedding menggunakan pre-trained SBERT  \n",
    "Tidak dilakukan stemming atau stopword removal dalam implementasi dasar ini.\n",
    "\n",
    "### 3.5 Perancangan Sistem Chatbot Hybrid  \n",
    "Sistem chatbot terdiri dari dua tahap utama pencarian jawaban:\n",
    "1. **BM25 Retrieval:**  \n",
    "   Dilakukan pencarian awal berdasarkan kemiripan kata kunci (lexical matching) untuk mendapatkan kandidat pertanyaan yang relevan.\n",
    "2. **SBERT Reranking:**  \n",
    "   Kandidat hasil BM25 kemudian direranking berdasarkan kemiripan semantic menggunakan SBERT (Sentence-BERT) yang sudah pre-trained. Proses ini tanpa pelatihan ulang (training/fine-tuning).\n",
    "\n",
    "### 3.6 Integrasi STT dan TTS  \n",
    "- **Speech-to-Text (STT):** Menggunakan library SpeechRecognition untuk mengubah input suara menjadi teks.\n",
    "- **Text-to-Speech (TTS):** Menggunakan library pyttsx3 untuk memb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1df01d-d775-4383-85f5-950a2f43174e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
